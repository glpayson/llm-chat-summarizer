# Tokenization settings
CHUNK_SIZE = 15000  # tokens per chunk
ENCODING_NAME = "o200k_base"  # GPT-4o tokenizer

# OpenAI API settings
MODEL_NAME = "gpt-4o"
TEMPERATURE = 0.7
MAX_TOKENS = 2000  # Maximum tokens in response (~1300-1500 words)

# Default file paths
DEFAULT_OUTPUT_FILE = "final_summary.txt"
DEFAULT_SUMMARY_PROMPT_FILE = "default_summary_prompt.txt"
